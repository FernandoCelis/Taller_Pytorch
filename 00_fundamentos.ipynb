{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contenido\n",
    "1. Fundamentos\n",
    "2. Métricas\n",
    "3. TensorBoard\n",
    "4. Guardado de modelos\n",
    "5. Grad-Cam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from typing import List, Any, Optional"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensores y operaciones\n",
    "* `torch.tensor(a)` \n",
    "    * a = `7 ` \n",
    "    * a = `[ 2 , 3 ]`\n",
    "    * a =  `[ [1,2] , [3,4] ] `\n",
    "\n",
    "Otro concepto importante para los tensores es su atributo shape. La forma te dice cómo están dispuestos los elementos en su interior.\n",
    "\n",
    "* `.ndim` \n",
    "* `.shape`\n",
    "* `.dtype`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scalar = torch.tensor(7)\n",
    "vector = torch.tensor([7, 7])\n",
    "matrix = torch.tensor([[7, 8],[9, 10]])\n",
    "print(f\" Dim matrix: {matrix.ndim} \\n Shape vector : {vector.shape} \\n dtype scalar: {scalar.dtype}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div style=\"text-align:center\">\n",
    "  <img src=\"pytorch-different-tensor-dimensions.png\" alt=\"dim\" width=\"70%\">\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulación de tensores (operaciones tensoriales)\n",
    "En el aprendizaje profundo, los datos (imágenes, texto, vídeo, audio, estructuras de proteínas, etc.) se representan como tensores.\n",
    "Un modelo aprende investigando esos tensores y realizando una serie de operaciones (podrían ser más de 1.000.000) sobre los tensores para crear una representación de los patrones en los datos de entrada.\n",
    "\n",
    "1. Suma                 (+)  \n",
    "2. Resta                (-)  \n",
    "3. Multiplicación       (*)  \n",
    "4. Producto matricial   (@)  \n",
    "\n",
    "Una de las operaciones más comunes en los algoritmos de aprendizaje automático y aprendizaje profundo (como las redes neuronales) es la multiplicación de matrices. PyTorch implementa la funcionalidad de multiplicación de matrices en el método torch.matmul(). \n",
    "\n",
    " * `(3, 2) @ (3, 2) ` >   **X**\n",
    " * `(2, 3) @ (3, 2)`  > (2,2)\n",
    " * `(3, 2) @ (2, 3)`  > (3,3)\n",
    "\n",
    "Deben coincidir las dimensiones interiores! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor([1, 2, 3])\n",
    "\n",
    "print(f'La suma {tensor} + {tensor}         = {tensor+tensor}')\n",
    "print(f'La resta {tensor} - {tensor}        = {tensor-tensor}')\n",
    "print(f'El producto {tensor} * {tensor}     = {tensor*tensor}')\n",
    "\n",
    "#Observe cómo los valores del del tensor no se vieron afectados despues de operar\n",
    "# esto se debe a que los valores dentro del tensor no cambian a menos que sean reasignados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.multiply(tensor, 10)  #otra función para multiplicar elemento a elemneto\n",
    "print(tensor, \"*\", tensor, \"Es igual a\", tensor * tensor)\n",
    "\n",
    "\n",
    "#multiplicacion entre matrices\n",
    "torch.matmul(tensor, tensor)\n",
    "tensor@tensor == torch.matmul(tensor, tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_A = torch.tensor([[1, 2],\n",
    "                         [3, 4],\n",
    "                         [5, 6]], dtype=torch.float32)\n",
    "\n",
    "tensor_B = torch.tensor([[7, 10],\n",
    "                         [8, 11], \n",
    "                         [9, 12]], dtype=torch.float32)\n",
    "\n",
    "torch.matmul(tensor_A, tensor_B) # (Dará error)\n",
    "\n",
    "print(tensor_A)\n",
    "print(tensor_B)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que gran parte del aprendizaje profundo consiste en multiplicar y realizar operaciones sobre matrices y que las matrices tienen una regla estricta sobre qué formas y tamaños se pueden combinar, siendo uno de los errores más comunes con los que te encontrarás en el aprendizaje profundo son los desajustes de forma.\n",
    "\n",
    "Una de las formas de hacer esto es con una transposición (cambiar las dimensiones de un tensor dado).\n",
    "Puedes realizar transposiciones en PyTorch usando `torch.transpose(input, dim0, dim1) `- donde input es el tensor a transponer y dim0 y dim1 son las dimensiones a intercambiar.\n",
    "\n",
    "`tensor.T ` es la **transpuesta** del tensor  - donde tensor es el _tensor_ a transponer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"El tensor A \\n {tensor_A}  con dimensión {tensor_A.shape}\")\n",
    "print(f\"\\nEl tensor B \\n {tensor_B.T}  con dimensión {tensor_B.T.shape}\")\n",
    "\n",
    "\n",
    "print(f\"Multiplying: {tensor_A.shape} * {tensor_B.T.shape} <- inner dimensions match\\n\")\n",
    "print(\"Output:\\n\")\n",
    "output = torch.matmul(tensor_A, tensor_B.T)   #torch.mm(tensor_A, tensor_B.T) es otra forma\n",
    "print(output) \n",
    "print(f\"\\nOutput shape: {output.shape}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tipos de datos tensoriales\n",
    "Hay muchos tipos de datos tensoriales disponibles en PyTorch. El tipo más común (y generalmente el predeterminado) es torch.float32 o torch.float.Esto se conoce como \"punto flotante de 32 bits\". Pero también hay punto flotante de 16 bits (torch.float16 o torch.half) y Y muchos más (torch.float64 o torch.double). \n",
    "\n",
    "\n",
    "La precisión es la cantidad de detalles que se utilizan para describir un número.\n",
    "Cuanto mayor es el valor de precisión (8, 16, 32), más detalles y, por tanto, más datos se utilizan para expresar un número.\n",
    "Esto es importante en el aprendizaje profundo y la computación numérica porque se realizan muchas operaciones, y cuanto más detalle se tenga para calcular, más cálculo se tendrá que utilizar. Por tanto, los tipos de datos de menor precisión suelen ser más rápidos de calcular, pero sacrifican algo de rendimiento en métricas de evaluación como la precisión (más rápidos de calcular, pero menos precisos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_16_tensor = torch.tensor([3.0, 6.0, 9.0],\n",
    "                               dtype=torch.float16) # torch.half \n",
    "\n",
    "float_16_tensor.dtype\n",
    "# Create a tensor\n",
    "some_tensor = torch.rand(3, 4)\n",
    "\n",
    "# Find out details about it\n",
    "print(some_tensor)\n",
    "print(f\"Shape of tensor: {some_tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {some_tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {some_tensor.device}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generando Tensores\n",
    "Generar vectores es útil para inicializar modelos de aprendizaje automático, calcular métricas, explorar datos y optimizar algoritmos. Facilitan la manipulación y procesamiento eficiente de información en diversas aplicaciones.\n",
    "\n",
    "* `torch.zeros( size=(#,#)) `\n",
    "* ` torch.arange(start=0, end=10, step=9)`\n",
    "* `torch.ones( size=(#,#)) `\n",
    "* `torch.rand( size=(#,#)) `\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random_image_size_tensor = torch.rand(size=(224, 224, 3))\n",
    "random_image_size_tensor.shape, random_image_size_tensor.ndim\n",
    "# Create a tensor of all zeros\n",
    "zeros = torch.zeros(size=(3, 4))\n",
    "zeros, zeros.dtype\n",
    "\n",
    "# Create a tensor of all ones\n",
    "ones = torch.ones(size=(3, 4))\n",
    "ones, ones.dtype\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_tensor = torch.rand(size=(3, 4))\n",
    "random_tensor, random_tensor.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_to_ten = torch.arange(start=0, end=10, step=9)\n",
    "zero_to_ten"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A veces puedes querer un tensor de cierto tipo con la misma forma que otro tensor. Por ejemplo, un tensor de todos los ceros con la misma forma que un tensor anterior.\n",
    "\n",
    "Para ello puede utilizar `torch.zeros_like(entrada)` o `torch.ones_like(entrada)` que devuelven un tensor lleno de ceros o unos con la misma forma que la entrada respectivamente.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_zeros = torch.zeros_like(input=zero_to_ten) \n",
    "ten_zeros"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torchvision\n",
    "El paquete torchvision contiene conjuntos de datos, arquitecturas de modelos y transformaciones de imágenes habituales para la visión por computador. Los datos no siempre vienen en su forma procesada final que se requiere para el entrenamiento de algoritmos de aprendizaje automático. Utilizamos transformaciones para realizar alguna manipulación de los datos y hacerlos adecuados para el entrenamiento.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "\n",
    "data = torchvision.datasets.OxfordIIITPet(\n",
    "    root='data/', download=True  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = data[140]\n",
    "print(f\"image type: {type(image)}, label type: {type(label)}\")\n",
    "text_label = data.classes[label] # The data object has a list with the class names.\n",
    "title = f\"\"\"\\\n",
    "Image shape: ({image.height}, {image.width}, {len(image.getbands())})\n",
    "label: {text_label}\"\"\"\n",
    "\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(image)\n",
    "plt.axis('off')\n",
    "plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(images: List[Any], titles: Optional[List[str]] = None):\n",
    "    \"\"\"Plots a list of images with their corresponding titles if given.\"\"\"\n",
    "    num_images = len(images)\n",
    "    fig, axs = plt.subplots(ncols=num_images, figsize=(num_images*5, 5))\n",
    "    for ax, image in zip(axs.flat, images):\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(image.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geometría"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_224 = torchvision.transforms.Resize(size=(224, 224))\n",
    "resize_512 = torchvision.transforms.Resize(size=(512, 512))\n",
    "resize_128 = torchvision.transforms.Resize(size=(128, 128))\n",
    "\n",
    "resized_image_224 = resize_224(image)\n",
    "resized_image_512 = resize_512(image)\n",
    "resized_image_128 = resize_128(image)\n",
    "\n",
    "plot_images(\n",
    "    images=[image, resized_image_224, resized_image_512, resized_image_128], \n",
    "    titles=[\"Original\", \"Resized 224\", \"Resized 512\", \"Resized 128\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccrop_224 = torchvision.transforms.CenterCrop(size=(224, 224))\n",
    "ccrop_64 = torchvision.transforms.CenterCrop(size=(64, 64))\n",
    "ccrop_128 = torchvision.transforms.CenterCrop(size=(128, 128))\n",
    "\n",
    "resized_image_224 = ccrop_224(image)\n",
    "resized_image_64 = ccrop_64(image)\n",
    "resized_image_128 = ccrop_128(image)\n",
    "\n",
    "plot_images(\n",
    "    images=[image, resized_image_224, resized_image_64, resized_image_128], \n",
    "    titles=[\"Original\", \"Center Crop 224\", \"Center Crop 512\", \"Center Crop 128\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_resized_crop_224 = torchvision.transforms.RandomResizedCrop(size=(224, 224))\n",
    "\n",
    "random_rrc224_image_1 = random_resized_crop_224(image)\n",
    "random_rrc224_image_2 = random_resized_crop_224(image)\n",
    "random_rrc224_image_3 = random_resized_crop_224(image)\n",
    "\n",
    "plot_images(\n",
    "    images=[image, random_rrc224_image_1, random_rrc224_image_2, random_rrc224_image_3], \n",
    "    titles=[\"Original\", \"Random Resized Crop 224 Flip 1\", \"Random Resized Crop 224 Flip 2\", \"Random Resized Crop 224 Flip 3\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_rot = torchvision.transforms.RandomRotation(degrees=80)\n",
    "\n",
    "random_rot_image_1 = random_rot(image)\n",
    "random_rot_image_2 = random_rot(image)\n",
    "random_rot_image_3 = random_rot(image)\n",
    "\n",
    "plot_images(\n",
    "    images=[image, random_rot_image_1, random_rot_image_2, random_rot_image_3], \n",
    "    titles=[\"Original\", \"Random rotation 1\", \"Random rotation 2\", \"Random rotation 3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_vflip = torchvision.transforms.RandomVerticalFlip(p=0.5)\n",
    "\n",
    "random_vflip_image_1 = random_vflip(image)\n",
    "random_vflip_image_2 = random_vflip(image)\n",
    "random_vflip_image_3 = random_vflip(image)\n",
    "\n",
    "plot_images(\n",
    "    images=[image, random_vflip_image_1, random_vflip_image_2, random_vflip_image_3], \n",
    "    titles=[\"Original\", \"Random Vertical Flip 1\", \"Random Vertical Flip 2\", \"Random Vertical Flip 3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_pipeline = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.CenterCrop(size=(224, 224)),\n",
    "    torchvision.transforms.RandomRotation(degrees=45),\n",
    "    torchvision.transforms.Resize(size=(300, 300)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "transformed_images = [transforms_pipeline(image).numpy().transpose(1, 2, 0) for _ in range(3)]\n",
    "titles = [f\"Transforms pipeline image {i}\" for i in range(1, 4)]\n",
    "plot_images(images=transformed_images, titles=titles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray=torchvision.transforms.RandomGrayscale(p=0.7)(image)\n",
    "blur=torchvision.transforms.GaussianBlur(kernel_size=(91,91))(image)\n",
    "negative=torchvision.transforms.RandomInvert(p=0.5)(image)\n",
    "\n",
    "\n",
    "plot_images(\n",
    "    images=[image, gray, blur, negative], \n",
    "    titles=[\"Original\", \"Random Vertical Flip 1\", \"Random Vertical Flip 2\", \"Random Vertical Flip 3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solar=torchvision.transforms.RandomSolarize(100.2, p=1)(image)\n",
    "equa=torchvision.transforms.RandomEqualize(p=1)(image)\n",
    "poster = torchvision.transforms.RandomPosterize(1, p=1)(image)\n",
    "\n",
    "\n",
    "plot_images(\n",
    "    images=[image, solar, equa, poster], \n",
    "    titles=[\"Original\", \"Random Vertical Flip 1\", \"Random Vertical Flip 2\", \"Random Vertical Flip 3\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color=torchvision.transforms.ColorJitter(brightness = 10, contrast= 2, saturation= 3, hue= 0)\n",
    "color(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_pipeline = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.CenterCrop(size=(224, 224)),\n",
    "    torchvision.transforms.RandomRotation(degrees=45),\n",
    "    torchvision.transforms.Resize(size=(300, 300)),\n",
    "    torchvision.transforms.RandomHorizontalFlip(p=0.5)\n",
    "])\n",
    "\n",
    "transformed_images = [transforms_pipeline(image).numpy().transpose(1, 2, 0) for _ in range(3)]\n",
    "titles = [f\"Transforms pipeline image {i}\" for i in range(1, 4)]\n",
    "plot_images(images=transformed_images, titles=titles)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejercicio\n",
    "Crear una composición que haga transformaciones de manera aletoria usando unicamente librerias de pytorch."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requires_grad`\n",
    "\n",
    "* https://pytorch.org/docs/stable/generated/torch.Tensor.requires_grad_.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.1063, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3 , requires_grad=True).sum() #tensor con 3 valore random\n",
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_10060\\1042362539.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor( x + 2,requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor( x + 2,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.) None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_10060\\2906174535.py:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:491.)\n",
      "  print(x.grad, y.grad)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(9.0,requires_grad=True)\n",
    "y = x + 2\n",
    "z = y**2 \n",
    "z = (x+2)**2\n",
    "z.backward() \n",
    "print(x.grad, y.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{(y)}}{\\partial w} = \\frac{\\partial}{\\partial w} (w *3 +5) = 3 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(3, requires_grad=True) # Dará error \n",
    "x\n",
    "z = x+2 \n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: tensor(3)\n",
      "w: tensor(2., requires_grad=True)\n",
      "b: tensor(5., requires_grad=True)\n",
      "y: tensor(11., grad_fn=<AddBackward0>)\n",
      "x.grad : None\n",
      "w.grad : tensor(3.)\n",
      "b.grad : tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3)\n",
    "\n",
    "# create tensors with requires_grad = true\n",
    "w = torch.tensor(2.0, requires_grad = True)\n",
    "b = torch.tensor(5.0, requires_grad = True)\n",
    "\n",
    "# print the tensors\n",
    "print(\"x:\", x)\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "\n",
    "# define a function y for the above tensors\n",
    "y = w*x + b\n",
    "print(\"y:\", y)\n",
    "\n",
    "# Compute gradients by calling backward function for y\n",
    "y.backward()\n",
    "\n",
    "# Access and print the gradients w.r.t x, w, and b\n",
    "dx = x.grad\n",
    "dw = w.grad\n",
    "db = b.grad\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)\n",
    "print(\"b.grad :\", db)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones desactivan el gradiente:\n",
    "* x.requires_grad_(false)\n",
    "* x.detach()                => crea un nuevo vector con los mismos valores sin gradiente\n",
    "* with torch.no_grad():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5311,  0.2727, -0.6872], requires_grad=True)\n",
      "tensor([ 0.5311,  0.2727, -0.6872])\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "print(x2)\n",
    "x2.requires_grad_(False)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.5330, 2.8388, 0.7075], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "x2.detach\n",
    "print(x2+2)\n",
    "#print(x2.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0108,  0.9174, -2.1099], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "c = x2+x2\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.5075, -0.3602, -0.1568], requires_grad=True)\n",
      "tensor([-1.0149, -0.7204, -0.3136])\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    print(x2)\n",
    "    a= x2+x2\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights=torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "  model_output=(weights*3).sum()\n",
    "  model_output.backward()  #acumula\n",
    "\n",
    "  print(weights.grad)\n",
    "\n",
    "  #weights.grad.zero_() #reinicia el gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0,requires_grad=True)\n",
    "\n",
    "#forward and loss\n",
    "y_hat= w*x\n",
    "loss= (y_hat - y)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "#backward\n",
    "loss.backward() #calcula el gradiente\n",
    "print(w.grad)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5)=0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "#f = 2*x\n",
    "\n",
    "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True) \n",
    "\n",
    "#model predict\n",
    "def forward(x):\n",
    "  return w*x\n",
    "\n",
    "#loss =MSE\n",
    "def loss(y,y_predicted):\n",
    "  return ((y_predicted-y)**2).mean()\n",
    "\n",
    "print(f'prediction before training: f(5)={forward(5):.3f}')\n",
    "\n",
    "#training\n",
    "learning_rate=0.01\n",
    "n_iters=100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html?highlight=confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
      "Target:  tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6)\n",
    "#Inicialize the binary randomic values\n",
    "binary_samples = 20\n",
    "binary_classes = 2\n",
    "binary_output = torch.randn(binary_samples, binary_classes)\n",
    "binary_pred = torch.argmax(binary_output, 1)\n",
    "\n",
    "binary_target = torch.randint(0, high = binary_classes, size = (binary_samples,))\n",
    "print(f'Predict: {binary_pred}')\n",
    "print(f'Target:  {binary_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch confusion matrix: \n",
      " tensor([[5, 4],\n",
      "        [2, 9]]) \n",
      "\n",
      "TP 9, TN 5, FP 4, FN 2\n"
     ]
    }
   ],
   "source": [
    "#Create the confusion matrix and each TP, TN, FP and FN of the distribution\n",
    "binary_confmat = ConfusionMatrix(num_classes = 2, task=\"binary\")\n",
    "\n",
    "binary_cm = binary_confmat(binary_pred, binary_target)\n",
    "print(f'Pytorch confusion matrix: \\n {binary_cm} \\n')\n",
    "[binary_TN, binary_FP], [binary_FN, binary_TP] =  binary_confmat(binary_pred, binary_target)\n",
    "print('TP {}, TN {}, FP {}, FN {}'.format(binary_TP, binary_TN, binary_FP, binary_FN))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "  <img src=\"img/Confusion-matrix-and-performance-equations.png\" alt=\"dim\" width=\"80%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Binary accuracy: 0.699999988079071 \n",
      " Using confussion matrix: 0.7\n",
      " Precision: 0.692307710647583 \n",
      " Sensitivity: 0.8181818127632141 \n",
      " Specificity: 0.5555555820465088\n"
     ]
    }
   ],
   "source": [
    "# Calculating each metric by myself\n",
    "\n",
    "binary_accuracy = (binary_TP + binary_TN) / (binary_TP + binary_FP + binary_TN + binary_FN)\n",
    "binary_accuracy_cm = np.sum(np.diag(binary_cm)/np.sum(binary_cm.numpy()))\n",
    "\n",
    "print(' Binary accuracy: {} \\n Using confussion matrix: {}'.format(binary_accuracy, binary_accuracy_cm))\n",
    "\n",
    "binary_precision   = binary_TP / (binary_TP + binary_FP)\n",
    "binary_sensitivity = binary_TP / (binary_TP + binary_FN)\n",
    "binary_specificity = binary_TN / (binary_TN + binary_FP)\n",
    "\n",
    "print(' Precision: {} \\n Sensitivity: {} \\n Specificity: {}'.format(binary_precision, binary_sensitivity, binary_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7 \n",
      " Precision: 0.6923076923076923 \n",
      " Sensitivity: 0.8181818181818182 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sk-learn metrics\n",
    "b_acc = accuracy_score(binary_target, binary_pred)\n",
    "b_pre = precision_score(binary_target, binary_pred)\n",
    "b_rec = recall_score(binary_target, binary_pred)\n",
    "print(' Accuracy: {} \\n Precision: {} \\n Sensitivity: {} \\n'.format(b_acc, b_pre, b_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: tensor([2, 0, 2, 1, 3, 3, 0, 1, 3, 2, 1, 1, 2, 2, 3, 2, 3, 1, 2, 1])\n",
      "Target:  tensor([2, 3, 0, 1, 1, 3, 1, 1, 3, 2, 3, 3, 2, 2, 3, 0, 2, 3, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "#Inicialize the multi-class randomic values\n",
    "nb_samples = 20\n",
    "nb_classes = 4\n",
    "mc_output = torch.randn(nb_samples, nb_classes)\n",
    "mc_pred = torch.argmax(mc_output, 1)\n",
    "mc_target = torch.randint(0, high = nb_classes, size = (nb_samples,))\n",
    "print(f'Predict: {mc_pred}')\n",
    "print(f'Target:  {mc_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor(3) tensor(0)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(0) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(1) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(1) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(3) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.]])\n",
      "tensor(1) tensor(0)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.]])\n",
      "tensor(1) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.]])\n",
      "tensor(3) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 2.]])\n",
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 2., 0.],\n",
      "        [1., 0., 0., 2.]])\n",
      "tensor(3) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 2., 0.],\n",
      "        [1., 1., 0., 2.]])\n",
      "tensor(3) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 2., 0.],\n",
      "        [1., 2., 0., 2.]])\n",
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 3., 0.],\n",
      "        [1., 2., 0., 2.]])\n",
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 0.],\n",
      "        [1., 2., 0., 2.]])\n",
      "tensor(3) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 0.],\n",
      "        [1., 2., 0., 3.]])\n",
      "tensor(0) tensor(2)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 0.],\n",
      "        [1., 2., 0., 3.]])\n",
      "tensor(2) tensor(3)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 2., 0., 3.]])\n",
      "tensor(3) tensor(1)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]])\n",
      "tensor(1) tensor(2)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]])\n",
      "tensor(0) tensor(1)\n",
      "tensor([[0., 1., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]])\n",
      "Pytorch confusion matrix: \n",
      " tensor([[0., 1., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc_conf_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "for t, p in zip(mc_target, mc_pred):\n",
    "    print(t,p)\n",
    "    mc_conf_matrix[t, p] += 1\n",
    "    print(mc_conf_matrix)\n",
    "print(f'Pytorch confusion matrix: \\n {mc_conf_matrix} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch confusion matrix: \n",
      " tensor([[0., 1., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]]) \n",
      "\n",
      "Pytorch confusion matrix: \n",
      " tensor([[0, 1, 2, 0],\n",
      "        [1, 2, 1, 1],\n",
      "        [0, 0, 4, 1],\n",
      "        [1, 3, 0, 3]]) \n",
      "\n",
      "Sklearn multi-label confusion matrix\n",
      "  [[0 1 2 0]\n",
      " [1 2 1 1]\n",
      " [0 0 4 1]\n",
      " [1 3 0 3]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pytorch confusion matrix\n",
    "mc_conf_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "for t, p in zip(mc_target, mc_pred):\n",
    "    mc_conf_matrix[t, p] += 1\n",
    "print(f'Pytorch confusion matrix: \\n {mc_conf_matrix} \\n')\n",
    "\n",
    "mc_confmat = ConfusionMatrix(num_classes = 4,task=\"multiclass\")\n",
    "print(f'Pytorch confusion matrix: \\n {mc_confmat(mc_pred, mc_target)} \\n')\n",
    "\n",
    "\n",
    "# Sklearn confusion matrix\n",
    "mc_cm = confusion_matrix(mc_target.flatten(), mc_pred.flatten(), labels=[0,1,2,3])\n",
    "print(f'Sklearn multi-label confusion matrix\\n  {mc_cm} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0\n",
      "TP 0.0, TN 15.0, FP 2.0, FN 3.0\n",
      "Class 1\n",
      "TP 2.0, TN 11.0, FP 4.0, FN 3.0\n",
      "Class 2\n",
      "TP 4.0, TN 12.0, FP 3.0, FN 1.0\n",
      "Class 3\n",
      "TP 3.0, TN 11.0, FP 2.0, FN 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_10060\\250390074.py:9: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  mc_FP = mc_conf_matrix[idx, c].sum()\n",
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_10060\\250390074.py:11: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  mc_FN = mc_conf_matrix[c, idx].sum()\n"
     ]
    }
   ],
   "source": [
    "# Pytorch TP - TN - FP - FN for each class\n",
    "mc_TP = mc_conf_matrix.diag()\n",
    "for c in range(nb_classes):\n",
    "    idx = torch.ones(nb_classes).byte()\n",
    "    idx[c] = 0\n",
    "    # all non-class samples classified as non-class\n",
    "    mc_TN = mc_conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() \n",
    "    # all non-class samples classified as class\n",
    "    mc_FP = mc_conf_matrix[idx, c].sum()\n",
    "    # all class samples not classified as class\n",
    "    mc_FN = mc_conf_matrix[c, idx].sum()\n",
    "    \n",
    "    print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "        c, mc_TP[c], mc_TN, mc_FP, mc_FN))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn multi-label confusion matrix\n",
      " [[[15  2]\n",
      "  [ 3  0]]\n",
      "\n",
      " [[11  4]\n",
      "  [ 3  2]]\n",
      "\n",
      " [[12  3]\n",
      "  [ 1  4]]\n",
      "\n",
      " [[11  2]\n",
      "  [ 4  3]]]\n"
     ]
    }
   ],
   "source": [
    "#Sklearn  TP - TN - FP - FN for each class\n",
    "cm_ml = multilabel_confusion_matrix(mc_target, mc_pred)\n",
    "print('Sklearn multi-label confusion matrix\\n', cm_ml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchMetrics es una colección nativa de PyTorch de código abierto de métricas funcionales y modulares para evaluaciones simples de rendimiento. Hasta ahora se han implementado métricas manualmente y con sklearn. La información necesaria para implementar estas métricas se encuentran en su documentación.\n",
    "\n",
    "\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html \n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/precision.html\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/recall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: tensor([2, 0, 2, 1, 3, 3, 0, 1, 3, 2, 1, 1, 2, 2, 3, 2, 3, 1, 2, 1])\n",
      "Target:  tensor([2, 3, 0, 1, 1, 3, 1, 1, 3, 2, 3, 3, 2, 2, 3, 0, 2, 3, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "#Inicialize the multi-class randomic values\n",
    "nb_samples = 20\n",
    "nb_classes = 4\n",
    "mc_output = torch.randn(nb_samples, nb_classes)\n",
    "mc_pred = torch.argmax(mc_output, 1)\n",
    "mc_target = torch.randint(0, high = nb_classes, size = (nb_samples,))\n",
    "print(f'Predict: {mc_pred}')\n",
    "print(f'Target:  {mc_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4071)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "accuracy = MulticlassAccuracy(task=\"multiclass\", num_classes=4)\n",
    "accuracy(mc_pred, mc_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4071)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import MulticlassRecall\n",
    "\n",
    "\n",
    "metric = MulticlassRecall(num_classes=4)\n",
    "metric(mc_pred, mc_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

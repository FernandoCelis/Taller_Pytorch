{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requires_grad`\n",
    "\n",
    "* https://pytorch.org/docs/stable/generated/torch.Tensor.requires_grad_.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.randn(3 , requires_grad=True).sum() #tensor con 3 valore random\n",
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(x+2,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(9.0,requires_grad=True)\n",
    "y = x + 2\n",
    "z = y**2 \n",
    "z.backward() \n",
    "print(x.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{(y)}}{\\partial w} = \\frac{\\partial}{\\partial w} (w *3 +5) = 3 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(3)\n",
    "\n",
    "# create tensors with requires_grad = true\n",
    "w = torch.tensor(2.0, requires_grad = True)\n",
    "b = torch.tensor(5.0, requires_grad = True)\n",
    "\n",
    "# print the tensors\n",
    "print(\"x:\", x)\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "\n",
    "# define a function y for the above tensors\n",
    "y = w*x + b\n",
    "print(\"y:\", y)\n",
    "\n",
    "# Compute gradients by calling backward function for y\n",
    "y.backward()\n",
    "\n",
    "# Access and print the gradients w.r.t x, w, and b\n",
    "dx = x.grad\n",
    "dw = w.grad\n",
    "db = b.grad\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)\n",
    "print(\"b.grad :\", db)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones desactivan el gradiente:\n",
    "* x.requires_grad_(false)\n",
    "* x.detach()                => crea un nuevo vector con los mismos valores sin gradiente\n",
    "* with torch.no_grad():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "print(x2)\n",
    "x2.requires_grad_(False)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "print(x2)\n",
    "print(x2.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "c = x2+x2\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    print(x2)\n",
    "    a= x2+x2\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights=torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "  model_output=(weights*3).sum()\n",
    "  model_output.backward()  #acumula\n",
    "\n",
    "  print(weights.grad)\n",
    "\n",
    "  weights.grad.zero_() #reinicia el gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0,requires_grad=True)\n",
    "\n",
    "#forward and loss\n",
    "y_hat= w*x\n",
    "loss= (y_hat - y)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "#backward\n",
    "loss.backward() #calcula el gradiente\n",
    "print(w.grad)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f = 2*x\n",
    "\n",
    "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True) \n",
    "\n",
    "#model predict\n",
    "def forward(x):\n",
    "  return w*x\n",
    "\n",
    "#loss = MSE\n",
    "def loss(y,y_predicted):\n",
    " \n",
    "#training\n",
    "learning_rate=0.01\n",
    "n_iters=100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    \n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "\n",
    "\n",
    "    # update weights\n",
    "   \n",
    "\n",
    "    # zero the gradients after updating\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html?highlight=confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(6)\n",
    "#Inicialize the binary randomic values\n",
    "binary_samples = 20\n",
    "binary_classes = 2\n",
    "binary_output = torch.randn(binary_samples, binary_classes)\n",
    "binary_pred = torch.argmax(binary_output, 1)\n",
    "\n",
    "binary_target = torch.randint(0, high = binary_classes, size = (binary_samples,))\n",
    "print(f'Predict: {binary_pred}')\n",
    "print(f'Target:  {binary_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the confusion matrix and each TP, TN, FP and FN of the distribution\n",
    "binary_confmat = ConfusionMatrix(num_classes = 2,task=\"binary\")\n",
    "\n",
    "binary_cm = binary_confmat(binary_pred, binary_target)\n",
    "print(f'Pytorch confusion matrix: \\n {binary_cm} \\n')\n",
    "[binary_TN, binary_FP], [binary_FN, binary_TP] =  binary_confmat(binary_pred, binary_target)\n",
    "print('TP {}, TN {}, FP {}, FN {}'.format(binary_TP, binary_TN, binary_FP, binary_FN))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "  <img src=\"img/Confusion-matrix-and-performance-equations.png\" alt=\"dim\" width=\"80%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating each metric by myself\n",
    "\n",
    "binary_accuracy = (binary_TP + binary_TN) / (binary_TP + binary_FP + binary_TN + binary_FN)\n",
    "binary_accuracy_cm = np.sum(np.diag(binary_cm)/np.sum(binary_cm.numpy()))\n",
    "\n",
    "print(' Binary accuracy: {} \\n Using confussion matrix: {}'.format(binary_accuracy, binary_accuracy_cm))\n",
    "\n",
    "binary_precision   = binary_TP / (binary_TP + binary_FP)\n",
    "binary_sensitivity = binary_TP / (binary_TP + binary_FN)\n",
    "binary_specificity = binary_TN / (binary_TN + binary_FP)\n",
    "\n",
    "print(' Precision: {} \\n Sensitivity: {} \\n Specificity: {}'.format(binary_precision, binary_sensitivity, binary_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sk-learn metrics\n",
    "b_acc = accuracy_score(binary_target, binary_pred)\n",
    "b_pre = precision_score(binary_target, binary_pred)\n",
    "b_rec = recall_score(binary_target, binary_pred)\n",
    "print(' Accuracy: {} \\n Precision: {} \\n Sensitivity: {} \\n'.format(b_acc, b_pre, b_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "#Inicialize the multi-class randomic values\n",
    "nb_samples = 20\n",
    "nb_classes = 4\n",
    "mc_output = torch.randn(nb_samples, nb_classes)\n",
    "mc_pred = torch.argmax(mc_output, 1)\n",
    "mc_target = torch.randint(0, high = nb_classes, size = (nb_samples,))\n",
    "print(f'Predict: {mc_pred}')\n",
    "print(f'Target:  {mc_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch confusion matrix\n",
    "mc_conf_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "for t, p in zip(mc_target, mc_pred):\n",
    "    mc_conf_matrix[t, p] += 1\n",
    "print(f'Pytorch confusion matrix: \\n {mc_conf_matrix} \\n')\n",
    "\n",
    "mc_confmat = ConfusionMatrix(num_classes = 4,task=\"multiclass\")\n",
    "print(f'Pytorch confusion matrix: \\n {mc_confmat(mc_pred, mc_target)} \\n')\n",
    "\n",
    "\n",
    "# Sklearn confusion matrix\n",
    "mc_cm = confusion_matrix(mc_target.flatten(), mc_pred.flatten(), labels=[0,1,2,3])\n",
    "print(f'Sklearn multi-label confusion matrix\\n  {mc_cm} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch TP - TN - FP - FN for each class\n",
    "mc_TP = mc_conf_matrix.diag()\n",
    "for c in range(nb_classes):\n",
    "    idx = torch.ones(nb_classes).byte()\n",
    "    idx[c] = 0\n",
    "    # all non-class samples classified as non-class\n",
    "    mc_TN = mc_conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() \n",
    "    # all non-class samples classified as class\n",
    "    mc_FP = mc_conf_matrix[idx, c].sum()\n",
    "    # all class samples not classified as class\n",
    "    mc_FN = mc_conf_matrix[c, idx].sum()\n",
    "    \n",
    "    print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "        c, mc_TP[c], mc_TN, mc_FP, mc_FN))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sklearn  TP - TN - FP - FN for each class\n",
    "cm_ml = multilabel_confusion_matrix(mc_target, mc_pred)\n",
    "print('Sklearn multi-label confusion matrix\\n', cm_ml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchMetrics es una colección nativa de PyTorch de código abierto de métricas funcionales y modulares para evaluaciones simples de rendimiento. Hasta ahora se han implementado métricas manualmente y con sklearn. La información necesaria para implementar estas métricas se encuentran en su documentación.\n",
    "\n",
    "\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html \n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/precision.html\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/recall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "#Inicialize the multi-class randomic values\n",
    "nb_samples = 20\n",
    "nb_classes = 4\n",
    "mc_output = torch.randn(nb_samples, nb_classes)\n",
    "mc_pred = torch.argmax(mc_output, 1)\n",
    "mc_target = torch.randint(0, high = nb_classes, size = (nb_samples,))\n",
    "print(f'Predict: {mc_pred}')\n",
    "print(f'Target:  {mc_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = Accuracy(task=\"multiclass\", num_classes=4)\n",
    "accuracy(mc_pred, mc_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics.classification import MulticlassRecall\n",
    "\n",
    "\n",
    "metric = MulticlassRecall(num_classes=4)\n",
    "metric(mc_pred, mc_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

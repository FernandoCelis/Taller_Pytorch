{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `requires_grad`\n",
    "\n",
    "* https://pytorch.org/docs/stable/generated/torch.Tensor.requires_grad_.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.5583, grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3 , requires_grad=True).sum() #tensor con 3 valore random\n",
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_11476\\1293865451.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y = torch.tensor(x+2,requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "y = torch.tensor( x + 2,requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(22.) None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_11476\\2906174535.py:6: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more informations. (Triggered internally at aten\\src\\ATen/core/TensorBody.h:491.)\n",
      "  print(x.grad, y.grad)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(9.0,requires_grad=True)\n",
    "y = x + 2\n",
    "z = y**2 \n",
    "z = (x+2)**2\n",
    "z.backward() \n",
    "print(x.grad, y.grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial{(y)}}{\\partial w} = \\frac{\\partial}{\\partial w} (w *3 +5) = 3 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m x\n\u001b[0;32m      3\u001b[0m z \u001b[39m=\u001b[39m x\u001b[39m+\u001b[39m\u001b[39m2\u001b[39m \n\u001b[1;32m----> 4\u001b[0m z\u001b[39m.\u001b[39;49mbackward()\n",
      "File \u001b[1;32mc:\\Users\\Fernando Celis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[0;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[0;32m    489\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\Fernando Celis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:193\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    189\u001b[0m inputs \u001b[39m=\u001b[39m (inputs,) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(inputs, torch\u001b[39m.\u001b[39mTensor) \u001b[39melse\u001b[39;00m \\\n\u001b[0;32m    190\u001b[0m     \u001b[39mtuple\u001b[39m(inputs) \u001b[39mif\u001b[39;00m inputs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mtuple\u001b[39m()\n\u001b[0;32m    192\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[39mlen\u001b[39m(tensors))\n\u001b[1;32m--> 193\u001b[0m grad_tensors_ \u001b[39m=\u001b[39m _make_grads(tensors, grad_tensors_, is_grads_batched\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    194\u001b[0m \u001b[39mif\u001b[39;00m retain_graph \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n",
      "File \u001b[1;32mc:\\Users\\Fernando Celis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\autograd\\__init__.py:88\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mrequires_grad:\n\u001b[0;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m out\u001b[39m.\u001b[39mnumel() \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m     new_grads\u001b[39m.\u001b[39mappend(torch\u001b[39m.\u001b[39mones_like(out, memory_format\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mpreserve_format))\n\u001b[0;32m     90\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "x=torch.randn(3 , requires_grad=True)\n",
    "x\n",
    "z = x+2 \n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39m# create tensors with requires_grad = true\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m w \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mtensor(\u001b[39m2\u001b[39;49m, requires_grad \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m      5\u001b[0m b \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor(\u001b[39m5.0\u001b[39m, requires_grad \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      7\u001b[0m \u001b[39m# print the tensors\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(3)\n",
    "\n",
    "# create tensors with requires_grad = true\n",
    "w = torch.tensor(2, requires_grad = True)\n",
    "b = torch.tensor(5.0, requires_grad = True)\n",
    "\n",
    "# print the tensors\n",
    "print(\"x:\", x)\n",
    "print(\"w:\", w)\n",
    "print(\"b:\", b)\n",
    "\n",
    "# define a function y for the above tensors\n",
    "y = w*x + b\n",
    "print(\"y:\", y)\n",
    "\n",
    "# Compute gradients by calling backward function for y\n",
    "y.backward()\n",
    "\n",
    "# Access and print the gradients w.r.t x, w, and b\n",
    "dx = x.grad\n",
    "dw = w.grad\n",
    "db = b.grad\n",
    "print(\"x.grad :\", dx)\n",
    "print(\"w.grad :\", dw)\n",
    "print(\"b.grad :\", db)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las siguientes funciones desactivan el gradiente:\n",
    "* x.requires_grad_(false)\n",
    "* x.detach()                => crea un nuevo vector con los mismos valores sin gradiente\n",
    "* with torch.no_grad():\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.3222, -0.1314,  1.0303], requires_grad=True)\n",
      "tensor([ 0.3222, -0.1314,  1.0303])\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "print(x2)\n",
    "x2.requires_grad_(False)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.5915, 3.7555, 0.2695], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "x2.detach\n",
    "print(x2+2)\n",
    "#print(x2.detach())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2779,  1.9586,  0.4510], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "c = x2+x2\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.6409, -0.4536, -0.6829], requires_grad=True)\n",
      "tensor([ 1.2818, -0.9072, -1.3657])\n"
     ]
    }
   ],
   "source": [
    "x2=torch.randn(3,requires_grad=True)\n",
    "with torch.no_grad():\n",
    "    print(x2)\n",
    "    a= x2+x2\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights=torch.ones(4,requires_grad=True)\n",
    "for epoch in range(3):\n",
    "  model_output=(weights*3).sum()\n",
    "  model_output.backward()  #acumula\n",
    "\n",
    "  print(weights.grad)\n",
    "\n",
    "  #weights.grad.zero_() #reinicia el gradiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(1.0)\n",
    "y = torch.tensor(2.0)\n",
    "w = torch.tensor(1.0,requires_grad=True)\n",
    "\n",
    "#forward and loss\n",
    "y_hat= w*x\n",
    "loss= (y_hat - y)**2\n",
    "\n",
    "print(loss)\n",
    "\n",
    "#backward\n",
    "loss.backward() #calcula el gradiente\n",
    "print(w.grad)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction before training: f(5)=0.000\n",
      "epoch 1: w = 0.300, loss = 30.00000000\n",
      "epoch 11: w = 1.665, loss = 1.16278565\n",
      "epoch 21: w = 1.934, loss = 0.04506890\n",
      "epoch 31: w = 1.987, loss = 0.00174685\n",
      "epoch 41: w = 1.997, loss = 0.00006770\n",
      "epoch 51: w = 1.999, loss = 0.00000262\n",
      "epoch 61: w = 2.000, loss = 0.00000010\n",
      "epoch 71: w = 2.000, loss = 0.00000000\n",
      "epoch 81: w = 2.000, loss = 0.00000000\n",
      "epoch 91: w = 2.000, loss = 0.00000000\n",
      "Prediction after training: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "#f = 2*x\n",
    "\n",
    "X = torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y = torch.tensor([2,4,6,8],dtype=torch.float32)\n",
    "\n",
    "w = torch.tensor(0.0, dtype=torch.float32, requires_grad=True) \n",
    "\n",
    "#model predict\n",
    "def forward(x):\n",
    "  return w*x\n",
    "\n",
    "#loss =MSE\n",
    "def loss(y,y_predicted):\n",
    "  return ((y_predicted-y)**2).mean()\n",
    "\n",
    "print(f'prediction before training: f(5)={forward(5):.3f}')\n",
    "\n",
    "#training\n",
    "learning_rate=0.01\n",
    "n_iters=100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass\n",
    "    y_pred = forward(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(Y, y_pred)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    w.grad.zero_()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'epoch {epoch+1}: w = {w.item():.3f}, loss = {l.item():.8f}')\n",
    "\n",
    "print(f'Prediction after training: f(5) = {forward(5).item():.3f}')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas\n",
    "\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/confusion_matrix.html?highlight=confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "from torchmetrics import ConfusionMatrix\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import multilabel_confusion_matrix, confusion_matrix, accuracy_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: tensor([1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1])\n",
      "Target:  tensor([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(6)\n",
    "#Inicialize the binary randomic values\n",
    "binary_samples = 20\n",
    "binary_classes = 2\n",
    "binary_output = torch.randn(binary_samples, binary_classes)\n",
    "binary_pred = torch.argmax(binary_output, 1)\n",
    "\n",
    "binary_target = torch.randint(0, high = binary_classes, size = (binary_samples,))\n",
    "print(f'Predict: {binary_pred}')\n",
    "print(f'Target:  {binary_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch confusion matrix: \n",
      " tensor([[5, 4],\n",
      "        [2, 9]]) \n",
      "\n",
      "TP 9, TN 5, FP 4, FN 2\n"
     ]
    }
   ],
   "source": [
    "#Create the confusion matrix and each TP, TN, FP and FN of the distribution\n",
    "binary_confmat = ConfusionMatrix(num_classes = 2, task=\"binary\")\n",
    "\n",
    "binary_cm = binary_confmat(binary_pred, binary_target)\n",
    "print(f'Pytorch confusion matrix: \\n {binary_cm} \\n')\n",
    "[binary_TN, binary_FP], [binary_FN, binary_TP] =  binary_confmat(binary_pred, binary_target)\n",
    "print('TP {}, TN {}, FP {}, FN {}'.format(binary_TP, binary_TN, binary_FP, binary_FN))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align:center\">\n",
    "  <img src=\"img/Confusion-matrix-and-performance-equations.png\" alt=\"dim\" width=\"80%\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Binary accuracy: 0.699999988079071 \n",
      " Using confussion matrix: 0.7\n",
      " Precision: 0.692307710647583 \n",
      " Sensitivity: 0.8181818127632141 \n",
      " Specificity: 0.5555555820465088\n"
     ]
    }
   ],
   "source": [
    "# Calculating each metric by myself\n",
    "\n",
    "binary_accuracy = (binary_TP + binary_TN) / (binary_TP + binary_FP + binary_TN + binary_FN)\n",
    "binary_accuracy_cm = np.sum(np.diag(binary_cm)/np.sum(binary_cm.numpy()))\n",
    "\n",
    "print(' Binary accuracy: {} \\n Using confussion matrix: {}'.format(binary_accuracy, binary_accuracy_cm))\n",
    "\n",
    "binary_precision   = binary_TP / (binary_TP + binary_FP)\n",
    "binary_sensitivity = binary_TP / (binary_TP + binary_FN)\n",
    "binary_specificity = binary_TN / (binary_TN + binary_FP)\n",
    "\n",
    "print(' Precision: {} \\n Sensitivity: {} \\n Specificity: {}'.format(binary_precision, binary_sensitivity, binary_specificity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Accuracy: 0.7 \n",
      " Precision: 0.6923076923076923 \n",
      " Sensitivity: 0.8181818181818182 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#sk-learn metrics\n",
    "b_acc = accuracy_score(binary_target, binary_pred)\n",
    "b_pre = precision_score(binary_target, binary_pred)\n",
    "b_rec = recall_score(binary_target, binary_pred)\n",
    "print(' Accuracy: {} \\n Precision: {} \\n Sensitivity: {} \\n'.format(b_acc, b_pre, b_rec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: tensor([2, 0, 2, 1, 3, 3, 0, 1, 3, 2, 1, 1, 2, 2, 3, 2, 3, 1, 2, 1])\n",
      "Target:  tensor([2, 3, 0, 1, 1, 3, 1, 1, 3, 2, 3, 3, 2, 2, 3, 0, 2, 3, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "#Inicialize the multi-class randomic values\n",
    "nb_samples = 20\n",
    "nb_classes = 4\n",
    "mc_output = torch.randn(nb_samples, nb_classes)\n",
    "mc_pred = torch.argmax(mc_output, 1)\n",
    "mc_target = torch.randint(0, high = nb_classes, size = (nb_samples,))\n",
    "print(f'Predict: {mc_pred}')\n",
    "print(f'Target:  {mc_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.]])\n",
      "tensor(3) tensor(0)\n",
      "tensor([[0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(0) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(1) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(1) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 0.]])\n",
      "tensor(3) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [0., 1., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.]])\n",
      "tensor(1) tensor(0)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 1., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.]])\n",
      "tensor(1) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 1.]])\n",
      "tensor(3) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [1., 0., 0., 2.]])\n",
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 2., 0.],\n",
      "        [1., 0., 0., 2.]])\n",
      "tensor(3) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 2., 0.],\n",
      "        [1., 1., 0., 2.]])\n",
      "tensor(3) tensor(1)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 2., 0.],\n",
      "        [1., 2., 0., 2.]])\n",
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 3., 0.],\n",
      "        [1., 2., 0., 2.]])\n",
      "tensor(2) tensor(2)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 0.],\n",
      "        [1., 2., 0., 2.]])\n",
      "tensor(3) tensor(3)\n",
      "tensor([[0., 0., 1., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 0.],\n",
      "        [1., 2., 0., 3.]])\n",
      "tensor(0) tensor(2)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 0.],\n",
      "        [1., 2., 0., 3.]])\n",
      "tensor(2) tensor(3)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 2., 0., 3.]])\n",
      "tensor(3) tensor(1)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 0., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]])\n",
      "tensor(1) tensor(2)\n",
      "tensor([[0., 0., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]])\n",
      "tensor(0) tensor(1)\n",
      "tensor([[0., 1., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]])\n",
      "Pytorch confusion matrix: \n",
      " tensor([[0., 1., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "mc_conf_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "for t, p in zip(mc_target, mc_pred):\n",
    "    print(t,p)\n",
    "    mc_conf_matrix[t, p] += 1\n",
    "    print(mc_conf_matrix)\n",
    "print(f'Pytorch confusion matrix: \\n {mc_conf_matrix} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch confusion matrix: \n",
      " tensor([[0., 1., 2., 0.],\n",
      "        [1., 2., 1., 1.],\n",
      "        [0., 0., 4., 1.],\n",
      "        [1., 3., 0., 3.]]) \n",
      "\n",
      "Pytorch confusion matrix: \n",
      " tensor([[0, 1, 2, 0],\n",
      "        [1, 2, 1, 1],\n",
      "        [0, 0, 4, 1],\n",
      "        [1, 3, 0, 3]]) \n",
      "\n",
      "Sklearn multi-label confusion matrix\n",
      "  [[0 1 2 0]\n",
      " [1 2 1 1]\n",
      " [0 0 4 1]\n",
      " [1 3 0 3]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pytorch confusion matrix\n",
    "mc_conf_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "for t, p in zip(mc_target, mc_pred):\n",
    "    mc_conf_matrix[t, p] += 1\n",
    "print(f'Pytorch confusion matrix: \\n {mc_conf_matrix} \\n')\n",
    "\n",
    "mc_confmat = ConfusionMatrix(num_classes = 4,task=\"multiclass\")\n",
    "print(f'Pytorch confusion matrix: \\n {mc_confmat(mc_pred, mc_target)} \\n')\n",
    "\n",
    "\n",
    "# Sklearn confusion matrix\n",
    "mc_cm = confusion_matrix(mc_target.flatten(), mc_pred.flatten(), labels=[0,1,2,3])\n",
    "print(f'Sklearn multi-label confusion matrix\\n  {mc_cm} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0\n",
      "TP 0.0, TN 15.0, FP 2.0, FN 3.0\n",
      "Class 1\n",
      "TP 2.0, TN 11.0, FP 4.0, FN 3.0\n",
      "Class 2\n",
      "TP 4.0, TN 12.0, FP 3.0, FN 1.0\n",
      "Class 3\n",
      "TP 3.0, TN 11.0, FP 2.0, FN 4.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_11476\\250390074.py:9: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  mc_FP = mc_conf_matrix[idx, c].sum()\n",
      "C:\\Users\\Fernando Celis\\AppData\\Local\\Temp\\ipykernel_11476\\250390074.py:11: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at ..\\aten\\src\\ATen/native/IndexingUtils.h:28.)\n",
      "  mc_FN = mc_conf_matrix[c, idx].sum()\n"
     ]
    }
   ],
   "source": [
    "# Pytorch TP - TN - FP - FN for each class\n",
    "mc_TP = mc_conf_matrix.diag()\n",
    "for c in range(nb_classes):\n",
    "    idx = torch.ones(nb_classes).byte()\n",
    "    idx[c] = 0\n",
    "    # all non-class samples classified as non-class\n",
    "    mc_TN = mc_conf_matrix[idx.nonzero()[:, None], idx.nonzero()].sum() \n",
    "    # all non-class samples classified as class\n",
    "    mc_FP = mc_conf_matrix[idx, c].sum()\n",
    "    # all class samples not classified as class\n",
    "    mc_FN = mc_conf_matrix[c, idx].sum()\n",
    "    \n",
    "    print('Class {}\\nTP {}, TN {}, FP {}, FN {}'.format(\n",
    "        c, mc_TP[c], mc_TN, mc_FP, mc_FN))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sklearn multi-label confusion matrix\n",
      " [[[15  2]\n",
      "  [ 3  0]]\n",
      "\n",
      " [[11  4]\n",
      "  [ 3  2]]\n",
      "\n",
      " [[12  3]\n",
      "  [ 1  4]]\n",
      "\n",
      " [[11  2]\n",
      "  [ 4  3]]]\n"
     ]
    }
   ],
   "source": [
    "#Sklearn  TP - TN - FP - FN for each class\n",
    "cm_ml = multilabel_confusion_matrix(mc_target, mc_pred)\n",
    "print('Sklearn multi-label confusion matrix\\n', cm_ml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TorchMetrics es una colección nativa de PyTorch de código abierto de métricas funcionales y modulares para evaluaciones simples de rendimiento. Hasta ahora se han implementado métricas manualmente y con sklearn. La información necesaria para implementar estas métricas se encuentran en su documentación.\n",
    "\n",
    "\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html \n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/precision.html\n",
    "* https://torchmetrics.readthedocs.io/en/stable/classification/recall.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict: tensor([2, 0, 2, 1, 3, 3, 0, 1, 3, 2, 1, 1, 2, 2, 3, 2, 3, 1, 2, 1])\n",
      "Target:  tensor([2, 3, 0, 1, 1, 3, 1, 1, 3, 2, 3, 3, 2, 2, 3, 0, 2, 3, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "#Inicialize the multi-class randomic values\n",
    "nb_samples = 20\n",
    "nb_classes = 4\n",
    "mc_output = torch.randn(nb_samples, nb_classes)\n",
    "mc_pred = torch.argmax(mc_output, 1)\n",
    "mc_target = torch.randint(0, high = nb_classes, size = (nb_samples,))\n",
    "print(f'Predict: {mc_pred}')\n",
    "print(f'Target:  {mc_target}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4071)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "accuracy = MulticlassAccuracy(task=\"multiclass\", num_classes=4)\n",
    "accuracy(mc_pred, mc_target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4071)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchmetrics.classification import MulticlassRecall\n",
    "\n",
    "\n",
    "metric = MulticlassRecall(num_classes=4)\n",
    "metric(mc_pred, mc_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
